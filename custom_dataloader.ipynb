{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5a437a21",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from skimage import io, transform\n",
    "from torchvision import transforms, utils\n",
    "import re\n",
    "import matplotlib as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4e33ffce",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "landmarks_frame = pd.read_csv('/home/mumbot/tombs/smtesttomb/textblocks/dataprac.csv',  on_bad_lines='skip')\n",
    "csv_path = '/home/mumbot/tombs/smtesttomb/textblocks/dataprac.csv'\n",
    "img_path = '/home/mumbot/tombs/smtesttomb/textblocks/'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "73dc33f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "class imgDataset(Dataset):\n",
    "    def __init__(self, csv, root, transform = None):\n",
    "        self.landmarks_frame = landmarks_frame\n",
    "        self.root = root\n",
    "        self.transform = transform\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.landmarks_frame)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        if torch.is_tensor(idx):\n",
    "            idx = idx.tolist\n",
    "            \n",
    "        img_name = os.path.join(img_path,\n",
    "                        landmarks_frame.iloc[idx, 0])\n",
    "        image = io.imread(img_name, as_gray = True)\n",
    "        tensor = torch.from_numpy(image)\n",
    "        image = tensor.unsqueeze(dim=0)\n",
    "        \n",
    "        landmarks = self.landmarks_frame.iloc[idx, 5]\n",
    "        landmarks = landmarks.split(':')\n",
    "        landmarksx = landmarks[2]\n",
    "        m = re.search(r\"\\[([A-Za-z0-9_,]+)\\]\", landmarksx)\n",
    "        landmarksx = (m.group(1))\n",
    "        landmarksx = landmarksx.split(',')\n",
    "        landmarksy = landmarks[3]\n",
    "        m2 = re.search(r\"\\[([A-Za-z0-9_,]+)\\]\", landmarksy)\n",
    "        landmarksy = m2.group(1)\n",
    "        landmarksy = landmarksy.split(',')\n",
    "        landmarks = list(zip(landmarksx, landmarksy))\n",
    "        landmarks = np.array([landmarks])    ################ mayb switch to tensor\n",
    "        landmarks = landmarks.astype('float').reshape(-1,2)\n",
    "        landmarks = torch.from_numpy(landmarks)\n",
    "        \n",
    "        sample = {'image': image, 'landmarks': landmarks}\n",
    "        if self.transform:\n",
    "            sample = self.transform(sample)\n",
    "        return sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "50ea2ba7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 torch.Size([1, 4992, 3744]) torch.Size([18, 2])\n",
      "1 torch.Size([1, 4992, 3744]) torch.Size([17, 2])\n",
      "2 torch.Size([1, 4992, 3744]) torch.Size([19, 2])\n",
      "3 torch.Size([1, 4992, 3744]) torch.Size([20, 2])\n",
      "4 torch.Size([1, 4992, 3744]) torch.Size([14, 2])\n",
      "5 torch.Size([1, 4992, 3744]) torch.Size([16, 2])\n",
      "6 torch.Size([1, 4992, 3744]) torch.Size([30, 2])\n",
      "7 torch.Size([1, 4992, 3744]) torch.Size([38, 2])\n",
      "8 torch.Size([1, 4992, 3744]) torch.Size([20, 2])\n",
      "9 torch.Size([1, 4992, 3744]) torch.Size([34, 2])\n",
      "10 torch.Size([1, 4992, 3744]) torch.Size([34, 2])\n",
      "11 torch.Size([1, 4992, 3744]) torch.Size([15, 2])\n",
      "12 torch.Size([1, 4992, 3744]) torch.Size([11, 2])\n",
      "13 torch.Size([1, 4992, 3744]) torch.Size([26, 2])\n",
      "14 torch.Size([1, 4992, 3744]) torch.Size([9, 2])\n",
      "15 torch.Size([1, 4992, 3744]) torch.Size([22, 2])\n",
      "16 torch.Size([1, 4992, 3744]) torch.Size([23, 2])\n",
      "17 torch.Size([1, 4992, 3744]) torch.Size([12, 2])\n",
      "18 torch.Size([1, 4992, 3744]) torch.Size([28, 2])\n",
      "19 torch.Size([1, 4992, 3744]) torch.Size([12, 2])\n",
      "20 torch.Size([1, 4992, 3744]) torch.Size([21, 2])\n",
      "21 torch.Size([1, 4992, 3744]) torch.Size([13, 2])\n",
      "22 torch.Size([1, 4992, 3744]) torch.Size([17, 2])\n",
      "23 torch.Size([1, 4992, 3744]) torch.Size([10, 2])\n",
      "24 torch.Size([1, 4992, 3744]) torch.Size([8, 2])\n",
      "25 torch.Size([1, 4992, 3744]) torch.Size([38, 2])\n",
      "26 torch.Size([1, 4992, 3744]) torch.Size([16, 2])\n",
      "27 torch.Size([1, 4992, 3744]) torch.Size([31, 2])\n",
      "28 torch.Size([1, 4992, 3744]) torch.Size([31, 2])\n",
      "29 torch.Size([1, 4992, 3744]) torch.Size([28, 2])\n",
      "30 torch.Size([1, 4992, 3744]) torch.Size([34, 2])\n",
      "31 torch.Size([1, 4992, 3744]) torch.Size([14, 2])\n",
      "32 torch.Size([1, 4992, 3744]) torch.Size([27, 2])\n",
      "33 torch.Size([1, 4992, 3744]) torch.Size([27, 2])\n",
      "34 torch.Size([1, 4992, 3744]) torch.Size([18, 2])\n",
      "35 torch.Size([1, 4992, 3744]) torch.Size([24, 2])\n",
      "36 torch.Size([1, 4992, 3744]) torch.Size([31, 2])\n",
      "37 torch.Size([1, 4992, 3744]) torch.Size([9, 2])\n",
      "38 torch.Size([1, 4992, 3744]) torch.Size([11, 2])\n",
      "39 torch.Size([1, 4992, 3744]) torch.Size([20, 2])\n",
      "40 torch.Size([1, 4992, 3744]) torch.Size([24, 2])\n",
      "41 torch.Size([1, 4992, 3744]) torch.Size([13, 2])\n",
      "42 torch.Size([1, 4992, 3744]) torch.Size([13, 2])\n",
      "43 torch.Size([1, 4992, 3744]) torch.Size([14, 2])\n",
      "44 torch.Size([1, 4992, 3744]) torch.Size([23, 2])\n",
      "45 torch.Size([1, 4992, 3744]) torch.Size([27, 2])\n",
      "46 torch.Size([1, 4992, 3744]) torch.Size([36, 2])\n",
      "47 torch.Size([1, 4992, 3744]) torch.Size([24, 2])\n",
      "48 torch.Size([1, 4992, 3744]) torch.Size([19, 2])\n",
      "49 torch.Size([1, 4992, 3744]) torch.Size([12, 2])\n",
      "50 torch.Size([1, 4992, 3744]) torch.Size([33, 2])\n",
      "51 torch.Size([1, 4992, 3744]) torch.Size([32, 2])\n",
      "52 torch.Size([1, 4992, 3744]) torch.Size([11, 2])\n",
      "53 torch.Size([1, 4992, 3744]) torch.Size([22, 2])\n",
      "54 torch.Size([1, 4992, 3744]) torch.Size([18, 2])\n",
      "55 torch.Size([1, 4992, 3744]) torch.Size([18, 2])\n",
      "56 torch.Size([1, 4992, 3744]) torch.Size([19, 2])\n",
      "57 torch.Size([1, 4992, 3744]) torch.Size([22, 2])\n",
      "58 torch.Size([1, 4992, 3744]) torch.Size([22, 2])\n",
      "59 torch.Size([1, 4992, 3744]) torch.Size([16, 2])\n",
      "60 torch.Size([1, 4992, 3744]) torch.Size([28, 2])\n",
      "61 torch.Size([1, 4992, 3744]) torch.Size([8, 2])\n",
      "62 torch.Size([1, 4992, 3744]) torch.Size([14, 2])\n",
      "63 torch.Size([1, 4992, 3744]) torch.Size([10, 2])\n",
      "64 torch.Size([1, 4992, 3744]) torch.Size([18, 2])\n",
      "65 torch.Size([1, 4992, 3744]) torch.Size([22, 2])\n",
      "66 torch.Size([1, 4992, 3744]) torch.Size([7, 2])\n",
      "67 torch.Size([1, 4992, 3744]) torch.Size([17, 2])\n",
      "68 torch.Size([1, 4992, 3744]) torch.Size([14, 2])\n",
      "69 torch.Size([1, 4992, 3744]) torch.Size([10, 2])\n",
      "70 torch.Size([1, 4992, 3744]) torch.Size([7, 2])\n",
      "71 torch.Size([1, 4992, 3744]) torch.Size([8, 2])\n"
     ]
    }
   ],
   "source": [
    "# move the to tensor part to a callable function that acts after doing\n",
    "# the rest of the transforms i.e. transform = tranforms.Compose([Rescale[256],\n",
    "#                                                                RandomCrop(224) but don't do random crop cause of new collate_fn\n",
    "#                                                                ToTensor() as custom function where grayscale is acknowledged])\n",
    "\n",
    "\n",
    "img_landmark_dataset = imgDataset(csv_path, img_path)\n",
    "# add transform above like (csv, imgpath, transforms)\n",
    "\n",
    "\n",
    "for i in range(len(img_landmark_dataset)):\n",
    "    sample = img_landmark_dataset[i]\n",
    "    \n",
    "    print(i, sample['image'].size(), sample['landmarks'].size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "81d7bec8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "72\n",
      "{'image': tensor([[[255, 255, 255,  ..., 255, 255, 255],\n",
      "         [255, 255, 255,  ..., 255, 255, 255],\n",
      "         [255, 255, 255,  ..., 255, 255, 255],\n",
      "         ...,\n",
      "         [255, 255, 255,  ..., 255, 255, 255],\n",
      "         [255, 255, 255,  ..., 255, 255, 255],\n",
      "         [255, 255, 255,  ..., 255, 255, 255]]], dtype=torch.uint8), 'landmarks': tensor([[1182., 3442.],\n",
      "        [1645., 3450.],\n",
      "        [2452., 3446.],\n",
      "        [2572., 3391.],\n",
      "        [2584., 2800.],\n",
      "        [2548., 1945.],\n",
      "        [2572., 1657.],\n",
      "        [2520., 1454.],\n",
      "        [2564., 1330.],\n",
      "        [2440., 1318.],\n",
      "        [1693., 1310.],\n",
      "        [1186., 1330.],\n",
      "        [1146., 1749.],\n",
      "        [1150., 2332.],\n",
      "        [1154., 2987.],\n",
      "        [1158., 3279.],\n",
      "        [1182., 3442.],\n",
      "        [1186., 3434.]], dtype=torch.float64)}\n"
     ]
    }
   ],
   "source": [
    "print(len(img_landmark_dataset))\n",
    "print(img_landmark_dataset[0])\n",
    "\n",
    "#  add transformers custom here if ya wan em'\n",
    "#  add compose func here to combine and apply all transformers \n",
    "# to the samples in the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ab84917a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#this is our custom collate_fn class and a show function\n",
    "\n",
    "from torch.nn.utils.rnn import pad_sequence \n",
    "\n",
    "#class PadCollate(Dataset):\n",
    "#    def __init__(self, pad_idx):\n",
    "#        self.pad_idx = pad_idx\n",
    "#    def __call__(self, batch):\n",
    "#        image = [d['image'] for d in data]\n",
    "#        landmarks = [d['landmarks'] for d in data]\n",
    "#        \n",
    "#        landmarks = pad_sequence(landmarks, batch_first = True)\n",
    "#        image = image\n",
    "        \n",
    "#        return {\n",
    "#            'image': image,\n",
    "#            'landmarks': landmarks\n",
    "#        }\n",
    "\n",
    "# either make a call for PadCollate where dataloader takes PadCollate with the\n",
    "# transformers and ToTensor transforms (and remove torch.from_numpy from the dataset)\n",
    "# ** look into batch_first = true/false **\n",
    "\n",
    "# OR\n",
    "\n",
    "# make a new collate_fn that has a torch.cat func in it\n",
    "    \n",
    "    \n",
    "def show_image_batch(image, title=None):\n",
    "    num = len(image)\n",
    "    fig = plt.figure()\n",
    "    for i in range(num):\n",
    "        ax = fig.add_subplot(1, num, i+1)\n",
    "        ax.imshow(image[i].numpy().transpose([1,2,0]))\n",
    "        ax.set_title(title[i])\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "9fd4ecb9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<torch.utils.data.dataloader.DataLoader object at 0x7f5770a49b50>\n",
      "18\n"
     ]
    },
    {
     "ename": "NotImplementedError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNotImplementedError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_3127/1261583678.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_loader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_loader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m \u001b[0;32mfor\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtrain_loader\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.9/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    519\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sampler_iter\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    520\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 521\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    522\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_yielded\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    523\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_kind\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0m_DatasetKind\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIterable\u001b[0m \u001b[0;32mand\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.9/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    559\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    560\u001b[0m         \u001b[0mindex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 561\u001b[0;31m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_fetcher\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    562\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pin_memory\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    563\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.9/site-packages/torch/utils/data/_utils/fetch.py\u001b[0m in \u001b[0;36mfetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     50\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 52\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcollate_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/tmp/ipykernel_3127/1263326209.py\u001b[0m in \u001b[0;36mPadCollate\u001b[0;34m(Dataset)\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mPadCollate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mDataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 21\u001b[0;31m     \u001b[0mimage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0md\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'image'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0md\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     22\u001b[0m     \u001b[0mlandmarks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0md\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'landmarks'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0md\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_3127/1263326209.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mPadCollate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mDataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 21\u001b[0;31m     \u001b[0mimage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0md\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'image'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0md\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     22\u001b[0m     \u001b[0mlandmarks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0md\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'landmarks'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0md\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.9/site-packages/torch/utils/data/dataset.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, index)\u001b[0m\n\u001b[1;32m     67\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     68\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__getitem__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mT_co\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 69\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mNotImplementedError\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     70\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     71\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__add__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mother\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m'Dataset[T_co]'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;34m'ConcatDataset[T_co]'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNotImplementedError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# a generator that loads data using pytorch DataLoader and custom collate_fn\n",
    "# if i get a bigger dataset lets set pin_memory = True, but right now \n",
    "# it's defaulted to False I think \n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(img_landmark_dataset, \n",
    "                          batch_size = 4,\n",
    "                          shuffle = True, \n",
    "                          collate_fn = PadCollate,\n",
    "                          drop_last=True\n",
    "                         )\n",
    "print(train_loader)\n",
    "print(len(train_loader))\n",
    "for data in train_loader:\n",
    "    print(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4a7b6788",
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_landmarks_barch(sample_batched):\n",
    "    #show landmarks with sample for a batch of samples\n",
    "    images_batch, landmarks_batch = \\\n",
    "        sample_batched['image'], sample_batched['landmarks']\n",
    "    batch_size = len(images_batched)\n",
    "    im_size = images_batch.size\n",
    "    grid_border_size = 2\n",
    "    \n",
    "    grid = utils.make_grid(images_batch)\n",
    "    plt.imshow(grid.numpy().transpose((1,2,0))) #idk if i need this line bc mine are already tensors from the dataset\n",
    "    for i in range(batch_size):\n",
    "        plt.scatter(landmarks_batch[i, :, 1].numpy() + i * im_size + (i + 1) * grid_border_size,\n",
    "                   landmarks_batch[i, :, 1].numpy() + grid_border_size,\n",
    "                   s = 10, marker = '.', c = 'r')\n",
    "        plt.title('Batch from dataloader')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "2c394dda",
   "metadata": {},
   "outputs": [
    {
     "ename": "NotImplementedError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNotImplementedError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_3127/2117386862.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi_batch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_batched\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_loader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m     print(i_batch, sample_batched['image'].size(),\n\u001b[0m\u001b[1;32m      3\u001b[0m           sample_batched['landmarks'].size())\n\u001b[1;32m      4\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mi_batch\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m         \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfigure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.9/site-packages/torch/utils/data/dataset.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, index)\u001b[0m\n\u001b[1;32m     67\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     68\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__getitem__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mT_co\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 69\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mNotImplementedError\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     70\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     71\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__add__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mother\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m'Dataset[T_co]'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;34m'ConcatDataset[T_co]'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNotImplementedError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for i_batch, sample_batched in enumerate(train_loader): \n",
    "    print(i_batch, sample_batched['image'].size(),\n",
    "          sample_batched['landmarks'].size())\n",
    "    if i_batch == 3:\n",
    "        plt.figure()\n",
    "        show_landmarks_batch(sample_batched)\n",
    "        plt.axis('off')\n",
    "        plt.show()\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d3c8ff19",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "73018fcc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd9342c4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "810255d0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab4599a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" bib:\n",
    "\n",
    "cat for collate_fn: https://pytorch.org/docs/stable/generated/torch.cat.html\n",
    "\n",
    "collate_fn for variable len. tensors: https://pytorch.org/docs/stable/data.html\n",
    "\n",
    "collate_fn ex: https://stackoverflow.com/questions/65279115/how-to-use-collate-fn-with-dataloaders\n",
    "\n",
    "collate_fn ex: https://discuss.pytorch.org/t/how-to-create-a-dataloader-with-variable-size-input/8278/3?u=ptrblck\n",
    "\n",
    "collate_fn ex w/ pad_sequences function: https://discuss.pytorch.org/t/how-to-use-collate-fn/27181/5\n",
    "\n",
    "pad_sequence torch doc: https://pytorch.org/docs/stable/generated/torch.nn.utils.rnn.pad_sequence.html#:~:text=pad_sequence%20stacks%20a%20list%20of,number%20of%20elements%20in%20sequences%20.\n",
    "\n",
    "collate_fn as a function not a call: https://discuss.pytorch.org/t/how-to-create-batches-of-a-list-of-varying-dimension-tensors/50773/14\n",
    "\n",
    "medium article on custom collate_fn: https://python.plainenglish.io/understanding-collate-fn-in-pytorch-f9d1742647d3\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
